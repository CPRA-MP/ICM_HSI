#ICM imports
import ICM_HelperFunctions as hf
import ICM_Settings as icm

#Python imports
import datetime as dt
import numpy as np
import os


def HSIyearlyVars(year):

    #TODO check, update this as needed when globals are implemented
    HSI_standalone = icm.HSI_standalone
    startyear = icm.startyear
    endyear = icm.endyear
    runprefix = icm.runprefix
    vegetation_dir = icm.vegetation_dir
    yll500 = icm.yll500
    xll500 = icm.xll500
    endyear = icm.endyear
    EHtemp_path = icm.EHtemp_path
    grid_output_file = icm.grid_output_file
    n500grid = icm.n500grid
    ecohydro_dir = icm.ecohydro_dir
    grid_comp = icm.grid_comp
    wetland_morph_dir = icm.wetland_morph_dir
    HSI_dir = icm.HSI_dir
    gridIDs = icm.gridIDs
    nvegtype = icm.nvegtype
    grid_ascii_file = icm.grid_ascii_file
    gridIDs = icm.gridIDs
    n500rows = icm.n500rows

    elapsedyear = year - startyear + 1
    
    veg_output_file = '%s_O_%02d_%02d_V_vegty.asc+' % (runprefix,elapsedyear,elapsedyear)
    veg_output_filepath = os.path.normpath(vegetation_dir + '/' + veg_output_file)

    #create dictionary with number of days for each month
    dom = hf.create_domdict(year)
       
    new_grid_file = hf.check_HSI_standalone(HSI_standalone,year,endyear)

    new_grid_filepath = os.path.normpath('%s/%s' % (EHtemp_path,new_grid_file)) # location of Morph output data grid file after it is generated in "WM.CalculateEcohydroAttributes"
    
    EH_grid_out_newfile = '%s_%s.%s' % (str.split(grid_output_file,'.')[0],year,str.split(grid_output_file,'.')[1])
    EH_grid_results_filepath = os.path.normpath('%s/%s' % (EHtemp_path,EH_grid_out_newfile)) # location of Hydro output data grid file
    

    print('\n--------------------------------------------------')
    print( '     PRE-PROCESSING HSI DATA FOR - YEAR %s' % year  )
    print('--------------------------------------------------\n')
    
    os.chdir(ecohydro_dir)

    # read in Morph output file
    print(' Reading in Morphology output files to be used for HSIs:')
    print('   - gridded summary data representing end-of-year conditions after Hydro-Veg-Morph')
    # import grid summary file (percent land, elevations) generated by Morphology
    griddata = np.genfromtxt(new_grid_filepath,delimiter=',',skip_header=1)
    
    # bedelevdict is a dictionary of mean elevation of water bottom (bed) portion of grid, key is gridID, noData = -9999
    # melevdict is a dictionary of mean elevation of marsh surface portion of grid, key is gridID, noData = -9999
    # landdict is a dictionary of percent land (0-100) in each 500-m grid cell, key is gridID
    # waterdict is a dictionary of percent water (0-100) in each 500-m grid cell, key is gridID
    # wetlanddict is a dictionary of percent wetland (0-100) (percet land - percent upland) in each 500-m grid cell, key is gridID
    bedelevdict = dict((int(griddata[n][0]),griddata[n][1]) for n in range(0,n500grid))
    melevdict   = dict((int(griddata[n][0]),griddata[n][2]) for n in range(0,n500grid))
    landdict    = dict((int(griddata[n][0]),griddata[n][3]) for n in range(0,n500grid))
    waterdict   = dict((int(griddata[n][0]),griddata[n][5]) for n in range(0,n500grid))
    
    #TODO not used check if needed
    wetlanddict = dict((int(griddata[n][0]),griddata[n][4]) for n in range(0,n500grid))

    # Post-process Ecohydro output for HSI calculations
    print(' Reading in Ecohydro output files to be used for HSIs:')
    print('   - annual compartment summary data')
    
    # import annual open water sediment deposition (mass/area) data by ICM-Hydro compartment (OW_sed_dep is 11th column in compartment_out_YYYY.csv)
    comp_summary_file = os.path.normpath(r'%s/TempFiles/compartment_out_%4d.csv' % (ecohydro_dir,year) )
    comp_summary_dict = hf.compout2dict(comp_summary_file,10)
    OWseddep_mass_dict = hf.comp2grid(comp_summary_dict,grid_comp)
    OWseddep_depth_mm_dict = {}
    BDWaterVal = 0.835              #ow_bd - bulk density of water bottoms (g/cm3)\n")
    # convert sediment deposition loading (kg/m2) to depth (mm) using bulk density of open water area (kg/m3)
    # if deposition is negative, that indicates erosion
    
    #  sed deposition in ICM-Hydro is calculated in g/m^2
    #  must convert to g/cm^2    ! [g/cm^2] = [g/m^2]*[m/100 cm]*[m/100 cm] = [g/m^2]/10000
    #  depth mineral deposition [cm] =  mineral depostion [g/cm2] / open water bed bulk density [g/cm3] 
    for n in grid_comp.keys():
        depo_g_cm2 = max(0.0,OWseddep_mass_dict[n]/10000.)  # seddep in ICM-Hydro is negative if eroded...only take positive values here for deposited depth
        depo_cm = depo_g_cm2/BDWaterVal 
        OWseddep_depth_mm_dict[n] = depo_cm/10.0
    
    del(OWseddep_mass_dict,comp_summary_dict)
    
    print('   - annual gridded summary data')
    
    # import annual Ecohydro output that is summarized by grid ID (Column 0 corresponds to 500m ID#, Column 7 is percent sand, and  Column 17 is average depth)    
    EH_grid_out = np.genfromtxt(EH_grid_results_filepath,delimiter=',',skip_header=1)
    #TODO check, next two dictionaries are not used
    stagedict =   dict((int(EH_grid_out[n][0]),EH_grid_out[n][12]) for n in range(0,n500grid))
    pctsanddict = dict((int(EH_grid_out[n][0]),EH_grid_out[n][7]) for n in range(0,n500grid))

    del(EH_grid_out)

    # Calculate monthly averages from Hydro output daily timeseries 
    # read in daily timeseries and calculate averages for each ICM-Hydro compartment for a variety of variables
    
    # check length of timeseries.out files once for year and save total length of file
    daily_timeseries_file = os.path.normpath(r'%s/SAL.out' % ecohydro_dir)
    if os.path.exists(daily_timeseries_file) == False:
        daily_timeseries_file = os.path.normpath(r'%s/%s_O_01_%02d_H_SAL.out' % (ecohydro_dir,runprefix,endyear-startyear+1) )
    
    ndays_run = hf.file_len(daily_timeseries_file)
      
    # build empty dictionaries that will be filled with monthly average values
    saldict, tmpdict, stgmndict = hf.build_dictionaries(gridIDs)

    # calculate monthly averages for compartment
    print('   - calculating monthly averages from daily timeseries compartment data')
    for mon in range(1,13):
        print('     - month: %02d' % mon)
        data_start = dt.date(startyear,1,1)          # start date of all data included in the daily timeseries file (YYYY,M,D)
        ave_start = dt.date(year,mon,1)          # start date of averaging window, inclusive (YYYY,M,D)
        ave_end = dt.date(year,mon,dom[mon])          # end date of averaging window, inclusive (YYYY,M,D)
        
        ##############
        # Salinity   
        ##############
        saldict = hf.monthly_mean_salinity(saldict,ecohydro_dir,runprefix,endyear,startyear,ndays_run, data_start,ave_end,ave_start,gridIDs,grid_comp)
    
        ##############
        # Temperature 
        ##############
        tmpdict = hf.monthly_mean_temp(tmpdict,ecohydro_dir,runprefix,endyear,startyear,ndays_run, data_start,ave_end,ave_start,gridIDs,grid_comp)
        
        ##############
        # Monthly Stage 
        ##############
        stgmndict = hf.monthly_mean_stage(stgmndict,ecohydro_dir,runprefix,endyear,startyear,ndays_run, data_start,ave_end,ave_start,gridIDs,grid_comp)
        


    # run HSI function (run in HSI directory so output files are saved there)
    os.chdir(HSI_dir)

    # import percent edge output from geomorph routine that is summarized by grid ID
    pctedge_file = os.path.normpath('%s/%s_N_%02d_%02d_W_pedge.csv'% (HSI_dir,runprefix,elapsedyear,elapsedyear)) # this must match name set in "WM.CalculateEcohydroAttributes" with the exception of (year) here instead of CurrentYear
    pedge = np.genfromtxt(pctedge_file,delimiter = ',',skip_header = 1)
    pctedgedict = dict((int(pedge[n][0]),pedge[n][1]) for n in range(0,n500grid))
    del(pedge)
    
    # years when oyster cultch map is re-calculated from previous Oyster HSI outputs
    OYE_cultch_update_years = [1,3,13,23,33,43]
    oyr2use = OYE_cultch_update_years[np.searchsorted(OYE_cultch_update_years,elapsedyear,side='right')-1]
                                             
    # if new decade (or end of spin-up period) build new Cultch map from previous oyster HSI outputs
    if elapsedyear in OYE_cultch_update_years:
        ave_cultch = {}
        # during spin up period (e.g. before second year listed in OYE_cultch_update_years), set cultch to optimal value
        if elapsedyear < OYE_cultch_update_years[1]:
            for n in grid_comp.keys():
                ave_cultch[n] = 1.0
        # after spinup, update cultch by setting equal to the average oyster HSI values since last cultch update was made
        else:
            ey_index = OYE_cultch_update_years.index(elapsedyear)
            years4update = OYE_cultch_update_years[ey_index] - OYE_cultch_update_years[ey_index-1]
            for n in grid_comp.keys():
                ave_cultch[n] = 0.0
            for oyr in range(elapsedyear-years4update,elapsedyear):
                OYSE_filepath = os.path.normpath(r'%s/%s_O_%02d_%02d_X_OYSTE.csv'% (HSI_dir,runprefix,oyr,oyr))
                oyr_OYSE = np.genfromtxt(OYSE_filepath,delimiter=',',skip_header=1,dtype='str')
                for row in oyr_OYSE:
                    gr = int(row[0])
                    oHSI = float(row[1])
                    ave_cultch[gr] += oHSI/years4update  # after looping over all years4update, each grid cell's value will be the average cultch
        
        file2write = os.path.normpath(r'%s/OysterCultch_%02d.csv'% (HSI_dir,elapsedyear))
        with open(file2write,mode='w') as fo:
            a = fo.write('GRID_ID,REEF_PCT,SEED_PCT,CULTCH_PCT,LEASE_PCT,PCT_CULTCH\n')
            for n in grid_comp.keys():
                a = fo.write('%d,0,0,0,0,%d\n' % (n,100.*ave_cultch[n]) ) # cultch file is in integers and we only need the last column populated with the average HSI - fill all other columns with 0

        
    # generate cultch surface from pre-existing Cultch map file written every 10 years
    cultch_file = os.path.normpath(r'%s/OysterCultch_%02d.csv'% (HSI_dir,oyr2use))
    cultchdict = {}
    cnp = np.genfromtxt(cultch_file,skip_header=True,usecols=(0,5),delimiter=',')
    for row in cnp:
        gid = int(row[0])
        cultchdict[gid] = row[1]/100.0      # cultch is used in HSI.py as a ratio from 0-1.0 so divide by 100 here to convert from percent to ratio

#TODO check, if needed
# print statements to check all keys are imported and correct format (should all be integers)    
#    print( len(landdict.keys()),min(landdict.keys()),max(landdict.keys()) )
#    print( len(waterdict.keys()),min(waterdict.keys()),max(waterdict.keys()) )
#    print( len(melevdict.keys()),min(melevdict.keys()),max(melevdict.keys()) )
#    print( len(wetlanddict.keys()),min(wetlanddict.keys()),max(wetlanddict.keys()) )
#    print( len(OWseddep_depth_mm_dict.keys()),min(OWseddep_depth_mm_dict.keys()),max(OWseddep_depth_mm_dict.keys()) )
#    print( len(depthdict.keys()),min(depthdict.keys()),max(depthdict.keys()) )
#    print( len(stagedict.keys()),min(stagedict.keys()),max(stagedict.keys()) )
#    print( len(pctsanddict.keys()),min(pctsanddict.keys()),max(pctsanddict.keys()) )
#    print( len(saldict.keys()),min(saldict.keys()),max(saldict.keys()) )
#    print( len(tmpdict.keys()),min(tmpdict.keys()),max(tmpdict.keys()) )
#    print( len(pctedgedict.keys()),min(pctedgedict.keys()),max(pctedgedict.keys()) )
#    print( len(cultchdict.keys()),min(cultchdict.keys()),max(cultchdict.keys()) )



    # set some general variables
    print( ' Setting up HSI runs.')

    asc_outprefix = '%s/%s_O_%02d_%02d_X_' % (HSI_dir,runprefix,elapsedyear,elapsedyear)
    csv_outprefix = '%s/%s_O_%02d_%02d_X_' % (HSI_dir,runprefix,elapsedyear,elapsedyear)

    sav_asc_file = '%s/output/%s_O_%02d_%02d_W_SAV.asc' % (wetland_morph_dir,runprefix,elapsedyear,elapsedyear)

    e = 2.718281828

    # calculate average elevation for grid cell from values for marsh elev and bed elev imported separately
    grid_elv_ave = {}
    for n in gridIDs:
        use_water = 0
        use_land = 0
        if waterdict[n] > 0:
            if bedelevdict != -9999:
                use_water = 1   # have values for both percent water and bed elevation
        if landdict[n] > 0:
            if bedelevdict != -9999:
                use_land = 1    # have values for both percent land and marsh elevation

        if use_water == 1:
            if use_land == 1:   # have both land and water data - calculate weighted mean elevation
                grid_elv_ave[n] = ( bedelevdict[n]*waterdict[n] + melevdict[n]*landdict[n] ) / (waterdict[n] + landdict[n])
            else:               # have only water data
                grid_elv_ave[n] = bedelevdict[n]
        elif use_land == 1:   # have only land data
                grid_elv_ave[n] = melevdict[n]
        else:               # do not have land or water data
            grid_elv_ave[n] = -9999

    #    sed_JanDec_sm = dict((n,OWseddep_depth_mm_dict[n][1]) for n in range(1,n500grid+1))
    #    sed_JanDec_sm = dict((n,np.sum([OWseddep_depth_mm_dict[n][jan],OWseddep_depth_mm_dict[n][feb],OWseddep_depth_mm_dict[n][mar],OWseddep_depth_mm_dict[n][apr],OWseddep_depth_mm_dict[n][may],OWseddep_depth_mm_dict[n][jun],OWseddep_depth_mm_dict[n][jul],OWseddep_depth_mm_dict[n][aug],OWseddep_depth_mm_dict[n][sep],OWseddep_depth_mm_dict[n][octb],OWseddep_depth_mm_dict[n][nov],OWseddep_depth_mm_dict[n][dec]]))for n in range(1,n500grid+1))

    # read in Veg output file - this is the same code that is used in WM.ImportVegResults()
    print( ' Reading in LAVegMod output files to be used for HSIs.')
        
    # skipvalue is the number of rows contained in the header and the grid array located at the start of the Veg output file
    skipvalue = n500rows + 7

    # generate zeros array that will be filled with Veg results
    vegcolumns = nvegtype + 12   #veg columns is the number of vegetation types (including flotant/dead flt/bare flt) plus CellID, Water, NotMod,BareGround (old and new), FFIBS score, and percent vegetation type summary values
    new_veg = np.zeros((n500grid,vegcolumns))
    veg_missing = 0
    # open Vegetation output file
    with open(veg_output_filepath,'r') as vegfile:
    # skip ASCII header rows and ASCII grid at start of output file
        for n in range(0,skipvalue-1):
            #TODO this is never used
            dump=vegfile.readline()
    # read in header of Vegetation output at bottom of ASCII grid    
        vegtypenames = vegfile.readline().split(',')
    # remove any leading or trailing spaces in veg types
        for n in range(0,len(vegtypenames)):
            vegtypenames[n] = vegtypenames[n].lstrip().rstrip()
    # loop through rest of Vegetation file         
        for nn in range(0,n500grid):
    # split each line of file based on comma delimiter (any spaces will be removed with rstrip,lstrip)
            vline = vegfile.readline().split(",")
    # if all columns have data in output file, assign veg output to veg_ratios array
            if (len(vline) == vegcolumns):
                for nnn in range(0,len(vline)):
                    new_veg[nn,nnn]=float(vline[nnn].lstrip().rstrip())
    # if there are missing columns in line, set first column equal to grid cell, and set all other columns equal to 0.
            else:
                for nnn in range(1,vegcolumns):
                    new_veg[nn,0]=nn+1
                    new_veg[nn,nnn] = 0.0
                veg_missing += 1
    if (veg_missing > 0):
        print( ' Some Vegetation output was not written correctly to Veg output file.')
        print('  - %s 500m grid cells did not have complete results in Veg Output file.' % veg_missing)



    print( ' Reclassifying Veg species output into general LULC types used by HSI equations.')
    # generate some blank dictionaries that will be filled with Veg output
    wetlndict = {}
    frattdict = {}
    frfltdict = {}
    interdict = {}
    brackdict = {}
    salmardict = {}
    swfordict = {}
    btfordict = {}
    baldcypdict = {}
    blackmangrovedict = {}
    marshelderdict = {}
    baredict = {}
    bare_mult = {}
    fresh_for_mult = {}
    land_mult = {}
    uplanddict = {}
    watsavdict = {}

    sav_in = np.genfromtxt(sav_asc_file,skip_header=6,delimiter=' ',dtype='str')
    grid_in = np.genfromtxt(grid_ascii_file,skip_header=6,delimiter=' ',dtype='str')
    nl = 0
    #TODO line not used
    for line in grid_in:
        nc = 0
        for nc in range(0,len(grid_in[nl])):
            gridID = int(grid_in[nl][nc])
            watsavdict[gridID] = float(sav_in[nl][nc])
            nc += 1
        nl += 1  
                

    # determine portion of cell that is covered by water, land, and different wetland types
    for n in range(0,len(new_veg)):
        gridID = int(new_veg[n][0])
        
        # use landdict to assign portion of cell that is water - this value is the updated land/water ratio AFTER the Morph run, 'WATER' value from Veg output is not needed here
        # landdict is bare land, vegetated land, and upland - it does not include water or floating marsh
    
    #TODO check if needed
    # check that percent land is Data (-9999 if NoData), if NoData, set water area to zero
    #        try:
    #            if landdict[gridID] >= 0:
    #                waterdict[gridID] = 100 - landdict[gridID]
    #            else:
    #                waterdict[gridID] = 0
    #        except:
    #            waterdict[gridID] = 0
        
        pland = landdict[gridID]/100.0
        
        # pland is the percentage of the grid cell that is land (as calculated by ICM-Morph)
        # the pL_XX values included in the ICM-LAVegMod output files are the 'portion of land that is habitat type X'
        # these pL_XX values in ICM-LAVegMod are the respective portion of VEGETATED LAND covered by habitat type - so water, NotMod, and Bareground are excluded from pL_XX calculations
        btfordict[gridID]           = pland*new_veg[n][vegtypenames.index('pL_BF')]             # % Bottomland Hardwood Forest
        swfordict[gridID]           = pland*new_veg[n][vegtypenames.index('pL_SF')]             # % Bottomland Hardwood Forest
        frattdict[gridID]           = pland*new_veg[n][vegtypenames.index('pL_FM')]             # % Fresh Herbaceous Marsh
        interdict[gridID]           = pland*new_veg[n][vegtypenames.index('pL_IM')]             # % Intermediate Herbaceous marsh
        brackdict[gridID]           = pland*new_veg[n][vegtypenames.index('pL_BM')]             # % Brackish Herbaceous Marsh
        salmardict[gridID]          = pland*new_veg[n][vegtypenames.index('pL_SM')]             # % Saline Herbaceous Marsh                
        
        # below species-specific outputs from ICM-LAVegMod are reported out as percentage of grid cell that - NO NEED TO MULTIPLY BY PLAND
        baldcypdict[gridID]         = new_veg[n][vegtypenames.index('TADI2')]                   # % Bald cypress
        blackmangrovedict[gridID]   = new_veg[n][vegtypenames.index('AVGE')]                    # % Black mangrove
        marshelderdict[gridID]      = new_veg[n][vegtypenames.index('IVFR')]                    # % Marsh elder
        frfltdict[gridID]           = new_veg[n][vegtypenames.index('ELBA2_Flt')]       \
                                        + new_veg[n][vegtypenames.index('PAHE2_Flt')]             # Live floating marsh LULC
        baredict[gridID]            = new_veg[n][vegtypenames.index('BAREGRND_Flt')]    \
                                        + new_veg[n][vegtypenames.index('BAREGRND_OLD')]  \
                                        + new_veg[n][vegtypenames.index('BAREGRND_NEW')]          # % Bareground (including bare flotant)
        wetlndict[gridID]           = 1.0 - ( baredict[gridID]                          \
                                            + new_veg[n][vegtypenames.index('WATER')]   \
                                            + new_veg[n][vegtypenames.index('NOTMOD')] )       # % Marsh Wetland (all types, including flotant)
        
        uplanddict[gridID]          = new_veg[n][vegtypenames.index('NOTMOD')]                 # % upland/developed (classified as NOTMOD in LAVegMod)
        # set land multiplier to zero for grid cells that are 100% land
        if waterdict[gridID] == 0.0:
            land_mult[gridID] = 0.0
        else:
            land_mult[gridID] = 1.0
        
    # Check for bareground - if there is no wetland or forest type, but there is bareground, set bareground multiplier to zero
        bare_mult[gridID] = 1.0
        if baredict[gridID] > 0.0:
            if wetlndict[gridID] == 0.0:
                if btfordict[gridID] == 0.0:
                    if watsavdict[gridID] == 0.0:
                        bare_mult[gridID] = 0.0
    # if there is wetland area, and it is greater than forested area, add bareground to wetland area
            elif wetlndict[gridID] > btfordict[gridID]:
                wetlndict[gridID] += baredict[gridID]
            # if forest is greater than wetland area, add bareground to foreseted areas (both swamp forest and bottom hardwood - since they are set equal)
            else:
                btfordict[gridID] += baredict[gridID]
                swfordict[gridID] += baredict[gridID]

    # if fresh forest is present and greater than wetland area, set fresh forest multiplier to zero
        fresh_for_mult[gridID] = 1.0
        if btfordict[gridID] > 0.0:
            # print('g:',gridID,'b:',btfordict[gridID],'w:',wetlndict[gridID])
            if btfordict[gridID] > wetlndict[gridID]:
                fresh_for_mult[gridID] = 0.0


    # convert marsh/land type dictionaries from portion (0-1) to percentage (0-100)
    for gridID in gridIDs:
        wetlndict[gridID]   =  max(0.0,min(100.0,100.0*wetlndict[gridID]))
        btfordict[gridID]   =  max(0.0,min(100.0,100.0*btfordict[gridID]))
        swfordict[gridID]   =  max(0.0,min(100.0,100.0*swfordict[gridID]))
        frattdict[gridID]   =  max(0.0,min(100.0,100.0*frattdict[gridID]))
        interdict[gridID]   =  max(0.0,min(100.0,100.0*interdict[gridID]))
        brackdict[gridID]   =  max(0.0,min(100.0,100.0*brackdict[gridID]))
        salmardict[gridID]  =  max(0.0,min(100.0,100.0*salmardict[gridID]))
        watsavdict[gridID]  =  max(0.0,min(100.0,100.0*watsavdict[gridID]))
        frfltdict[gridID]   =  max(0.0,min(100.0,100.0*frfltdict[gridID]))
        baldcypdict[gridID] =  max(0.0,min(100.0,100.0*baldcypdict[gridID]))

    return csv_outprefix,asc_outprefix,land_mult,fresh_for_mult,bare_mult, saldict, tmpdict,\
            wetlndict,btfordict,swfordict,frattdict,interdict,brackdict,salmardict,\
                watsavdict,frfltdict,baldcypdict,cultchdict,waterdict 